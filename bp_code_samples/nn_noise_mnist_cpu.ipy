# coding: utf-8
import torch
import torchvision
import torchvision.transforms as transforms

from torchdp import PrivacyEngine

num_epochs=10
learning_rate=0.001
clipRate = 4.0
epsilon = 0.5
bs = 4

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5), (0.5))])
	 
trainset = torchvision.datasets.MNIST(root='./dataMnist', train=True,
                                        download=True, transform=transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=0)

testset = torchvision.datasets.MNIST(root='./dataMnist', train=False,
                                       download=True, transform=transform)

testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=0)

#classes = ('plane', 'car', 'bird', 'cat',
#           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

classes = ('0','1','2','3','4','5','6','7','8','9')

import matplotlib.pyplot as plt
import numpy as np

# functions to show an image


#def imshow(img):
#    img = img / 2 + 0.5     # unnormalize
#    npimg = img.numpy()
#    plt.imshow(np.transpose(npimg, (1, 2, 0)))
#    plt.show()


# get some random training images
#dataiter = iter(trainloader)
#images, labels = dataiter.next()

# show images
#imshow(torchvision.utils.make_grid(images))
# print labels
#print(' '.join('%5s' % classes[labels[j]] for j in range(4)))

import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(28 * 28, 240)
		
        self.fc2 = nn.Linear(240, 120)
		
        self.fc3 = nn.Linear(120, 84)
        self.fc4 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = F.relu(self.fc3(x))
        x = self.fc4(x)
        return x


net = Net()
import torch.optim as optim

#criterion = nn.CrossEntropyLoss()
# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
#optimizer = optim.Adam(net.parameters(), lr=learning_rate)

#import torch.optim as optim

criterion = nn.CrossEntropyLoss()
#criterion = nn.CrossEntropyLoss(reduction='none')
# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
optimizer = optim.Adam(net.parameters(), lr=learning_rate)

privacy_engine = PrivacyEngine(
    net,
    bs,
    sample_size=len(trainloader.dataset),
    alphas=[1, 10, 100],
    noise_multiplier=epsilon,
    max_grad_norm=clipRate,
)

privacy_engine.attach(optimizer)

#net = Net()
        
#device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Assuming that we are on a CUDA machine, this should print a CUDA device:

#print(device)

#net.to(device)

accHistory = []
lossHistory = []
count = 0

for epoch in range(num_epochs):  # loop over the dataset multiple times

    count = 0
    running_loss = 0.0
    loss_values = []

    for i, data in enumerate(trainloader, 0):
        count += 1
	
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        #inputs, labels = data[0].to(device), data[1].to(device)
        inputs2 = inputs.view(-1,28*28)
        
#         print(inputs.size())

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
		#outputs = []
		#for i in range(inputs.size()[0]):
		#	outputs.append(net(inputs[i]))
        outputs = net(inputs2)
        
		
		#should get loss for each input
        #losses = []
        #print(outputs.size()[0])
        #print(labels.size())
        #print(labels)
        #print(outputs[0])
        #for i in range(outputs.size()[0]):
        #    losses.append(criterion(outputs[i],labels[i]))
		
        loss = criterion(outputs, labels)
        loss_values.append(loss.item())
		
        #if i % 2000 == 1999:    # print every 2000 mini-batches
        #    print('pre-clipping grad?: ',loss)
			
        #print(type(loss))
		
		#try grad clipping the loss for each input
        #for i in loss:
        #nn.utils.clip_grad_norm(loss,clipRate)
		
		#try noise injection
        #meanClippedGrad = torch.mean(loss,0,True)
        #noise = torch.normal(0,epsilon,size=meanClippedGrad.size())
		
        #finalGrad = meanClippedGrad + noise
		
        #if i % 2000 == 1999:    # print every 2000 mini-batches
        #    print('post-clipping grad?: ', finalGrad)
		
        loss.backward()
        #finalGrad.backward()
		
		#trying grad clipping
        #nn.utils.clip_grad_norm(net.parameters(), clipRate)
		
		#try noise injection
		#noise = torch.normal(torch.tensor([0.0]),torch.tensor([epsilon]))
		#noise = torch.normal(0,epsilon,size=)
		
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            #epoch_loss = running_loss / 2000
            running_loss = 0.0
            
    correct = 0
    total = 0
    #with torch.no_grad():
    for data in testloader:
        im, la = data
        #           images, labels = data[0].to(device), data[1].to(device)
        im2 = im.view(-1,28*28)
        o = net(im2)
        #l = criterion(o,la)
			
        _, predicted = torch.max(o.data, 1)
        total += la.size(0)
        correct += (predicted == la).sum().item()

    #print('Accuracy of the network on the 10000 test images: %d %%' % (
        #100 * correct / total))
    accHistory.append(100 * correct / total)
	
    lossHistory.append(np.mean(loss_values))
    loss_values.clear()
    #lossHistory.append(l)

print('Finished Training')

print('Accuracy over Epochs')
plt.plot(range(0,num_epochs,1),accHistory)
plt.suptitle('Acc over Epochs')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

print('Loss over Epochs')
plt.plot(range(0,num_epochs,1),lossHistory)
plt.suptitle('Loss over Epochs')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.show()

#PATH = './gpu_cifar_net.pth'
#torch.save(net.state_dict(), PATH)

#dataiter = iter(testloader)
#images, labels = dataiter.next()

# print images
#imshow(torchvision.utils.make_grid(images))
#print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))

#net = Net()
#net.load_state_dict(torch.load(PATH))

#outputs = net(images.view(-1,3*32*32))

#_, predicted = torch.max(outputs, 1)

#print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]
#                              for j in range(4)))

#net.to(device)
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
#        images, labels = data[0].to(device), data[1].to(device)
        images2 = images.view(-1,28*28)
        outputs = net(images2)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))

#print(device)

class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        #images, labels = data[0].to(device), data[1].to(device)
        outputs = net(images.view(-1,28*28))
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1


for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))
